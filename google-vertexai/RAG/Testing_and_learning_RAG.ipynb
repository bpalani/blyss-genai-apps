{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMOHBQX30MufFg4wAPH4e/1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bpalani/blyss-genai-apps/blob/main/google-vertexai/RAG/Testing_and_learning_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RAG using LangChain Stuff Documents Chain and ChromaDB\n",
        "\n",
        "*   Load document from web and store in ChromaDB\n",
        "*   Use LangChain Stuff document chain to retrieve information relevant to user\n",
        "\n"
      ],
      "metadata": {
        "id": "sRrvZfarvbTl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tiz29MFRmnw5",
        "outputId": "0dddd245-e868-49fc-f462-e37f66d96c2f",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.9/433.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.4 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.17 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.1/89.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "#####  Installing required packages including LangChain, Google Genai (from LangChain) and ChromaDB\n",
        "!pip install -q langchain==0.3.23\n",
        "!pip install -q langchain-core==0.3.54\n",
        "!pip install -q langchain-community==0.3.21\n",
        "!pip install -q langchain-text-splitters==0.3.8\n",
        "!pip install -q langchain-google-genai==2.1.1\n",
        "!pip install -q chromadb==1.0.5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### Set GOOGLE_API_KEY\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY"
      ],
      "metadata": {
        "id": "HcHjRrDNFrpR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### Define the LLM\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0.3, max_retries=2)"
      ],
      "metadata": {
        "id": "oSMEC2fCndAB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### Load RecursiveURL output, split into chunks & use embeddings to store in chromadb vector database\n",
        "from langchain_community.document_loaders import RecursiveUrlLoader\n",
        "from langchain.docstore.document import Document\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from typing import List\n",
        "\n",
        "def bs4_extractor(html: str) -> str:\n",
        "    soup = BeautifulSoup(html, \"lxml\")\n",
        "    return re.sub(r\"\\n\\n+\", \"\\n\\n\", soup.text).strip()\n",
        "\n",
        "def recursive_load_url(url: str) -> List[Document]:\n",
        "    loader = RecursiveUrlLoader(url, extractor=bs4_extractor)\n",
        "    docs = loader.load()\n",
        "    return docs\n",
        "doc_list = recursive_load_url(\"https://docs.influxdata.com/influxdb3/core/\")\n",
        "\n",
        "# split the documents into chunks\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "def chunk_docs(size:int, docs: List[Document] ) -> List[Document]:\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=size, chunk_overlap=100)\n",
        "    documents = text_splitter.split_documents(docs)\n",
        "    return documents\n",
        "\n",
        "doc_chunks = chunk_docs(800,doc_list)\n",
        "\n",
        "#load GoogleGenerativeAIEmbeddings model\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "gemini_embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "\n",
        "# save to vector database\n",
        "from langchain.vectorstores import Chroma\n",
        "vectorstore = Chroma.from_documents(\n",
        "                     documents=doc_chunks,                 # Data\n",
        "                     embedding=gemini_embeddings,    # Embedding model\n",
        "                     persist_directory=\"./influxdb_docs.db\" # Directory to save data\n",
        "                     )\n",
        "\n",
        "print(f\"Finished storing {len(doc_chunks)} documents into vector database.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SG0P5CJmniLi",
        "outputId": "89a8956b-82aa-402f-be82-6ce8f04dab12"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished storing 68 documents into vector database.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "##### Prompt template to query Gemini\n",
        "llm_prompt_template = \"\"\"You are a researcher for answering user questions.\n",
        "Use the following context to answer the question.\n",
        "If you don't know the answer, just say that you don't know.\n",
        "Use as many sentences as possible to answer the user's question. Explain in detail if necessary.\\n\n",
        "Question: {question} \\nContext: {context} \\nAnswer:\"\"\"\n",
        "\n",
        "llm_prompt = PromptTemplate.from_template(llm_prompt_template)\n",
        "\n",
        "print(llm_prompt)"
      ],
      "metadata": {
        "id": "6_Lmin911djj",
        "outputId": "18a0d0ee-def7-4f53-9dd8-8f3863f73b81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_variables=['context', 'question'] input_types={} partial_variables={} template=\"You are a researcher for answering user questions.\\nUse the following context to answer the question.\\nIf you don't know the answer, just say that you don't know.\\nUse as many sentences as possible to answer the user's question. Explain in detail if necessary.\\n\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### Open vector database as retriever and use LCEL to create RAG stuff documents chain\n",
        "from langchain_core.tools import tool\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain.schema import StrOutputParser\n",
        "\n",
        "#Combine data from documents to readable string format.\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "@tool\n",
        "def retrieve_info(querystring:str) -> str:\n",
        "    \"\"\"Retrieves documentation information about InfluxDB 3 Core\"\"\"\n",
        "    #print(\"In retrieve_info function\")\n",
        "    # Expose index to the retriever\n",
        "    retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 20})\n",
        "\n",
        "    # Create stuff documents chain using LCEL.\n",
        "    #\n",
        "    # The chain implements the following pipeline:\n",
        "    # 1. Extract the website data relevant to the question from the Chroma\n",
        "    #    vector store and save it to the variable `context`.\n",
        "    # 2. `RunnablePassthrough` option to provide `question` when invoking\n",
        "    #    the chain.\n",
        "    # 3. The `context` and `question` are then passed to the prompt where they\n",
        "    #    are populated in the respective variables.\n",
        "    # 4. This prompt is then passed to the LLM (`gemini-2.0-flash`).\n",
        "    # 5. Output from the LLM is passed through an output parser\n",
        "    #    to structure the model's response.\n",
        "    rag_chain = (\n",
        "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "        | llm_prompt\n",
        "        | llm\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "    return rag_chain.invoke(querystring)"
      ],
      "metadata": {
        "id": "NgQ4xCkEEPiw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Welcome to InfluxDB 3 Core docs bot! What would like to do? (e.g., 'Write data', 'Query data', 'exit'): \")\n",
        "while True:\n",
        "    user_input = input(\"> \")\n",
        "    if user_input.lower() in (\"exit\"):\n",
        "        print(\"Thank you for using InfluxDB Docs Bot. Goodbye!\")\n",
        "        break\n",
        "    response = retrieve_info(user_input)\n",
        "    print((response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-r79YzLkJJre",
        "outputId": "75c68115-acfa-48b4-9b6d-4403dd36a642"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to InfluxDB 3 Core docs bot! What would like to do? (e.g., 'Write data', 'Query data', 'exit'): \n",
            "> how do i use python processing engine?\n",
            "To use the Python Processing Engine with InfluxDB 3, follow these steps:\n",
            "\n",
            "1.  **Activate the Processing Engine:** When starting the InfluxDB 3 Core server, include the `--plugin-dir <PLUGIN_DIR>` option. The PLUGIN_DIR is the file system location where you store plugin files for the Processing Engine.\n",
            "2.  **Create a Plugin:** A plugin is a Python function with a signature compatible with a Processing Engine trigger. This plugin will receive HTTP request headers and content, allowing it to parse, process, and send data to the database or third-party services.\n",
            "3.  **Create a Trigger:** When creating a trigger, you specify a plugin, a database, and optional arguments. Triggers define when the plugin is executed and what data it receives. There are different trigger types:\n",
            "\n",
            "    *   **On WAL flush:** Sends a batch of written data to a plugin.\n",
            "    *   **On Schedule:** Executes a plugin on a schedule.\n",
            "    *   **On Request:** Binds a plugin to a custom HTTP API endpoint.\n",
            "4.  **Test Your Plugin:** Use the `influxdb3 test wal_plugin` command to test your plugin. This allows you to see how the plugin behaves, what data it would write, and identify any errors.\n",
            "5.  **Create the Plugin and Trigger:** Use the `influxdb3 create trigger` command to create a trigger that runs the plugin.\n",
            "6.  **Enable the Trigger:**  After creating the plugin and trigger, use the command `influxdb3 enable trigger --database <database_name> <trigger_name>` to enable the trigger.\n",
            "> can you write me an example code for using processing engine?\n",
            "```python\n",
            "# This is the basic structure for Python plugin code that runs in the\n",
            "# InfluxDB 3 Processing engine.\n",
            "\n",
            "from influxdb_client_3 import LineBuilder\n",
            "\n",
            "def run(influxdb3_local, headers, content, arg1=None, arg2=None):\n",
            "    \"\"\"\n",
            "    This is the main function that will be called when the trigger is activated.\n",
            "\n",
            "    Args:\n",
            "        influxdb3_local: An object that allows you to interact with the local\n",
            "            InfluxDB 3 instance. It has methods for querying, writing, and\n",
            "            logging.\n",
            "        headers: A dictionary containing the HTTP request headers.\n",
            "        content: The HTTP request content (the data that triggered the plugin).\n",
            "        arg1: An optional argument passed to the trigger.\n",
            "        arg2: Another optional argument passed to the trigger.\n",
            "\n",
            "    Returns:\n",
            "        None\n",
            "    \"\"\"\n",
            "\n",
            "    # Log the headers and content for debugging purposes\n",
            "    influxdb3_local.info(\"headers: \" + str(headers))\n",
            "    influxdb3_local.info(\"content: \" + str(content))\n",
            "\n",
            "    # You can access trigger arguments like this:\n",
            "    influxdb3_local.info(\"arg1: \" + str(arg1))\n",
            "    influxdb3_local.info(\"arg2: \" + str(arg2))\n",
            "\n",
            "    # here we're using arguments provided at the time the trigger was set up\n",
            "    # to feed into parameters that we'll put into a query\n",
            "    query_params = {\"host\": \"foo\"}\n",
            "    # here's an example of executing a parameterized query. Only SQL is supported.\n",
            "    # It will query the database that the trigger is attached to by default. We'll\n",
            "    # soon have support for querying other DBs.\n",
            "    query_result = influxdb3_local.query(\"SELECT * FROM cpu where host = '$host'\", query_params)\n",
            "    # the result is a list of Dict that have the column name as key and value as\n",
            "    # value. If you run the WAL test plugin with your plugin against a DB that\n",
            "    # you've written data into, you'll be able to see some results\n",
            "    influxdb3_local.info(\"query result: \" + str(query_result))\n",
            "\n",
            "    # this shows building a line of LP to write back to the database. tags must go first and\n",
            "    # their order is important and must always be the same for each individual table. Then\n",
            "    # fields and lastly an optional time, which you can see in the next example below\n",
            "    line = LineBuilder(\"some_table\")\\\n",
            "        .tag(\"tag1\", \"tag1_value\")\\\n",
            "        .tag(\"tag2\", \"tag2_value\")\\\n",
            "        .int64_field(\"field1\", 1)\\\n",
            "        .float64_field(\"field2\", 2.0)\\\n",
            "        .string_field(\"field3\", \"number three\")\n",
            "\n",
            "    # this writes it back (it actually just buffers it until the completion of this function\n",
            "    # at which point it will write everything back that you put in)\n",
            "    influxdb3_local.write(line)\n",
            "\n",
            "    # here's another example, but with us setting a nanosecond timestamp at the end\n",
            "    other_line = LineBuilder(\"other_table\")\n",
            "    other_line.int64_field(\"other_field\", 1)\n",
            "    other_line.float64_field(\"other_field2\", 3.14)\n",
            "    other_line.time_ns(1302)\n",
            "\n",
            "    # and you can see that we can write to any DB in the server\n",
            "    influxdb3_local.write_to_db(\"mytestdb\", other_line)\n",
            "\n",
            "    # just some log output as an example\n",
            "    influxdb3_local.info(\"done\")\n",
            "```\n",
            "\n",
            "To use this plugin:\n",
            "\n",
            "1.  **Save the code:** Save the above code into a file, for example, `my_plugin.py`.  Place this file in the directory specified by the `--plugin-dir` option when starting the InfluxDB 3 Core server.  For example, if you start the server with `--plugin-dir /path/to/plugins`, then save the file as `/path/to/plugins/my_plugin.py`.\n",
            "2.  **Create a trigger:**  Use the `influxdb3 create trigger` command to create a trigger that uses this plugin.  You'll need to specify the database, the plugin name, a trigger specification (e.g., a table name), and any trigger arguments.  For example:\n",
            "\n",
            "    ```bash\n",
            "    influxdb3 create trigger \\\n",
            "      -d mydb \\\n",
            "      --plugin my_plugin \\\n",
            "      --trigger-spec \"table:foo\" \\\n",
            "      --trigger-arguments \"arg1=hello,arg2=world\" \\\n",
            "      trigger1\n",
            "    ```\n",
            "\n",
            "    This command creates a trigger named `trigger1` in the database `mydb`. It will run the `my_plugin` plugin when data is written to the `foo` table. The plugin will receive the arguments `arg1=hello` and `arg2=world`.  Make sure a database named `mydb` with a table named `foo` exists.\n",
            "3.  **Enable the trigger:** Use the `influxdb3 enable trigger` command to enable the trigger:\n",
            "\n",
            "    ```bash\n",
            "    influxdb3 enable trigger --database mydb trigger1\n",
            "    ```\n",
            "\n",
            "4.  **Write data:** Now, when you write data to the `foo` table in the `mydb` database, the `my_plugin` plugin will be executed.  The plugin will log the headers, content, and arguments, execute a query against the `cpu` table (assuming such a table exists and is populated), and write some sample data back to the `some_table` table in the default database and the `other_table` table in the `mytestdb` database.  Make sure a database named `mytestdb` exists.\n",
            "5.  **Test the plugin:** Before creating the trigger, you can test the plugin using the `influxdb3 test wal_plugin` command:\n",
            "\n",
            "    ```bash\n",
            "    influxdb3 test wal_plugin \\\n",
            "      --lp \"foo,tag1=value1 field1=1i\" \\\n",
            "      --database mydb \\\n",
            "      --input-arguments \"arg1=hello,arg2=world\" \\\n",
            "      my_plugin.py\n",
            "    ```\n",
            "\n",
            "    This command will run the `my_plugin.py` plugin with the provided line protocol data, database, and input arguments.  It will print the plugin's output to the console, allowing you to verify that it is working correctly.\n",
            "> can I import custom packages in the python code?\n",
            "Yes, you can import custom packages in your Python code within the InfluxDB 3 Processing engine. The documentation mentions that you can edit your Python code in the plugins directory, and the server reloads the file for every request to the test API. Additionally, the documentation provides an example of how to use the InfluxDB 3 Python library, which would require importing the `influxdb_client_3` package. It also recommends installing required packages in a Python virtual environment for your specific project, implying that you can manage and import custom packages as needed.\n",
            "> show me an example on how to do it?\n",
            "Here are a few examples of how to interact with InfluxDB 3 Core:\n",
            "\n",
            "1.  **Writing Data with Line Protocol:**\n",
            "\n",
            "    *   This example shows how to construct a line of Line Protocol (LP) to write data to the database. Tags must come first and maintain the same order for each table. Then come fields, and lastly, an optional timestamp.\n",
            "\n",
            "    ```python\n",
            "    line = LineBuilder(\"some_table\")\\\n",
            "        .tag(\"tag1\", \"tag1_value\")\\\n",
            "        .tag(\"tag2\", \"tag2_value\")\\\n",
            "        .int64_field(\"field1\", 1)\\\n",
            "        .float64_field(\"field2\", 2.0)\\\n",
            "        .string_field(\"field3\", \"number three\")\n",
            "    \n",
            "    influxdb3_local.write(line)\n",
            "    ```\n",
            "\n",
            "    *   Another example with a nanosecond timestamp:\n",
            "\n",
            "    ```python\n",
            "    other_line = LineBuilder(\"other_table\")\n",
            "    other_line.int64_field(\"other_field\", 1)\n",
            "    other_line.float64_field(\"other_field2\", 3.14)\n",
            "    other_line.time_ns(1302)\n",
            "    \n",
            "    influxdb3_local.write_to_db(\"mytestdb\", other_line)\n",
            "    ```\n",
            "2.  **Querying Data with SQL:**\n",
            "\n",
            "    *   This example demonstrates how to query data using SQL and process the results using PyArrow.\n",
            "\n",
            "    ```python\n",
            "    from influxdb_client_3 import InfluxDBClient3\n",
            "    \n",
            "    client = InfluxDBClient3(\n",
            "        host='http://localhost:8181',\n",
            "        database='servers'\n",
            "    )\n",
            "    \n",
            "    table = client.query(\n",
            "        query=\"SELECT * FROM cpu LIMIT 10\",\n",
            "        language=\"sql\"\n",
            "    )\n",
            "    \n",
            "    print(\"\\n#### View Schema information\\n\")\n",
            "    print(table.schema)\n",
            "    \n",
            "    print(\"\\n#### Use PyArrow to read the specified columns\\n\")\n",
            "    print(table.column('usage_active'))\n",
            "    print(table.select(['host', 'usage_active']))\n",
            "    print(table.select(['time', 'host', 'usage_active']))\n",
            "    ```\n",
            "3.  **Parameterized Queries:**\n",
            "\n",
            "    *   This example shows how to execute a parameterized query.\n",
            "\n",
            "    ```python\n",
            "    query_params = {\"host\": \"foo\"}\n",
            "    query_result = influxdb3_local.query(\"SELECT * FROM cpu where host = '$host'\", query_params)\n",
            "    influxdb3_local.info(\"query result: \" + str(query_result))\n",
            "    ```\n",
            "4.  **Creating a Last Value Cache:**\n",
            "\n",
            "    *   This example shows how to create a last value cache.\n",
            "\n",
            "    ```text\n",
            "    influxdb3 create last_cache \\\n",
            "      --database servers \\\n",
            "      --table cpu \\\n",
            "      --key-columns host,application \\\n",
            "      --value-columns usage_percent,status \\\n",
            "      --count 5 cpuCache\n",
            "    ```\n",
            "5.  **Querying a Distinct Values Cache:**\n",
            "\n",
            "    *   This example shows how to query a distinct values cache.\n",
            "\n",
            "    ```text\n",
            "    influxdb3 query \\\n",
            "      --database servers \\\n",
            "      \"SELECT * FROM distinct_cache('cpu', 'cpuDistinctCache')\"\n",
            "    ```\n",
            "6.  **Testing and Creating a Plugin:**\n",
            "\n",
            "    *   This example shows how to test a plugin and then create the plugin and trigger.\n",
            "\n",
            "    ```text\n",
            "    influxdb3 test wal_plugin \\\n",
            "      --lp \"my_measure,tag1=asdf f1=1.0 123\" \\\n",
            "      --database mydb \\\n",
            "      --input-arguments \"arg1=hello,arg2=world\" \\\n",
            "      test.py\n",
            "    \n",
            "    influxdb3 create trigger \\\n",
            "      -d mydb \\\n",
            "      --plugin test_plugin \\\n",
            "      --trigger-spec \"table:foo\" \\\n",
            "      --trigger-arguments \"arg1=hello,arg2=world\" \\\n",
            "      trigger1\n",
            "    ```\n",
            "> exit\n",
            "Thank you for using InfluxDB Docs Bot. Goodbye!\n"
          ]
        }
      ]
    }
  ]
}